routing_rules_source:  # Messages from MQTT to Kafka
  "/iot/sensor/light/#":  # MQTT topic to subscribe to
    encoding: "utf-8"  # utf-8 is the default, for all options available see column 'Codec' at https://docs.python.org/3/library/codecs.html#standard-encodings
    mq_qos: 0
    mq_deserialiser_topic: serdes.std_string  # {relative_path_to_module}, e.g. serdes.std_string (default), serdes.std_json, serdes.number_int, serdes.number_float, serdes.std_xml, serdes.cflt_json, serdes.cflt_avro
    mq_deserialiser_payload: serdes.std_json  # {relative_path_to_module}, e.g. serdes.std_string (default), serdes.std_json, serdes.number_int, serdes.number_float, serdes.std_xml, serdes.cflt_json, serdes.cflt_avro
    kafka_encoding: "utf-8"  # utf-8 is the default, for all options available see column 'Codec' at https://docs.python.org/3/library/codecs.html#standard-encodings
    kafka_topic: iot_sensor_light  # Kafka topic name where the MQTT data will be sent to
    kafka_topic_dlq: iot_sensor_light_dlq  # Kafka Dead Letter Queue topic name where the MQTT data will be sent to in case of any serdes error
    kafka_set_headers: tools.set_headers  # {relative_path_to_module}
    kafka_serialiser_key: serdes.cflt_avro | schemas/iot_sensor_data_light-key.json  # {relative_path_to_module} | {schema_filename}. In addition to the ones above: cflt_avro (default), cflt_json
    kafka_serialiser_value: serdes.cflt_avro | schemas/iot_sensor_data_light-value.json # {relative_path_to_module} | {schema_filename}. In addition to the ones above: cflt_avro (default), cflt_json
    stop_processing_if_matched: True
    smt:
      - set_value.vendor: "$topic.split('/', 4)"
      - set_value.mac_address: "$topic.split('/', -1)"
      - set_value.mqtt_topic: "$topic"
      - set_value.static_field: "I can be anything"
      - drop_value: "dummy_field"
      - set_header.static_header: "My static header"
      - drop_header: "mqtt.message.id"
      - key_as_json: "mqtt_topic"
      - set_key.static_Key: "My static key"
      - drop_key: "static_Key"
      - value_to_key.dynamic_Key: "static_field"
      - rename_key.mqtt_topic: "MQTT_Topic"
      - rename_header.mqtt.qos: "QoS"


routing_rules_sink:  # Messages from Kafka to MQTT
  "iot_data_reverse":  # Kafka topic to subscribe to
    encoding: "utf-8"  # utf-8 is the default, for all options available see column 'Codec' at https://docs.python.org/3/library/codecs.html#standard-encodings
    kafka_deserialiser_key: serdes.std_string  # {relative_path_to_module}. In addition to the ones above: cflt_avro (default), cflt_json
    kafka_deserialiser_value: serdes.std_json  # {relative_path_to_module}. In addition to the ones above: cflt_avro (default), cflt_json
    mq_serialiser_payload: serdes.std_json  # {relative_path_to_module}, e.g. serdes.std_string (default), serdes.std_json, serdes.number_int, serdes.number_float, serdes.std_xml, serdes.cflt_json, serdes.cflt_avro
    mq_topic: /my_prefix/+$key # $key, $value, $value.{field_name}, $header.{field_name}. Use "+" to concatenate strings, for example: /my_prefix/+$value.vendor/+$value.mac_address
    mq_payload: $value # $key, $key.{field_name}, $value, $value.{field_name}, $header.{field_name}
    mq_qos: 0


mqtt:
  host: "localhost"
  port: 1883
  keepalive: 60
  transport: "tcp"
  protocol: "MQTTv311" # MQTTv31, MQTTv311, MQTTv5
  reconnect_on_failure: True
  username: Null
  password: Null
  client_id: Null
  clean_session: True
  ca_certs: Null
  certfile: Null
  keyfile: Null
  cert_reqs: "CERT_NONE" # CERT_NONE, CERT_OPTIONAL, CERT_REQUIRED
  tls_version: Null # PROTOCOL_SSLv23, PROTOCOL_SSLv2, PROTOCOL_SSLv3, PROTOCOL_TLSv1, PROTOCOL_TLSv1_1, PROTOCOL_TLSv1_2


kafka_auth:
  bootstrap.servers: "localhost:9092"
  #security.protocol: "SASL_SSL"
  #sasl.mechanisms: "PLAIN"
  #sasl.username: "sasl_username"
  #sasl.password: "sasl_password"


kafka_producer:
  acks: "all"
  client.id: "mqtt2kafka"
  partitioner: "murmur2_random"
  enable.idempotence: True
  # Any other Kafka producer configuration set here will be applied


kafka_consumers:
  consumers: 6
  group.id: "mqtt2kafka-reverse"
  auto.offset.reset: "earliest"
  # Any other Kafka consumer configuration set here will be applied, except 'client.id' as it will be set as {group.id}-{sequential number from 0 to (consumers - 1)}


schema_registry:
  url: "http://localhost:8081"
  #basic.auth.user.info: "basic_auth:user_info"
